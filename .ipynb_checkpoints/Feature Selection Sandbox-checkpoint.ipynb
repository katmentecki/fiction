{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickle data successfully.\n"
     ]
    }
   ],
   "source": [
    "from application import db\n",
    "from application.models import *\n",
    "import pymysql\n",
    "from collections import Counter\n",
    "from config import USER, PWD\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "try:\n",
    "    feature_dicts = pickle.load( open( \"pickled_data/feature_dicts.p\", \"rb\" ) )\n",
    "    print(\"Loaded pickle data successfully.\")\n",
    "\n",
    "except:\n",
    "    print(\"Did not find feature data in pickle form. Creating pickle for future use.\")\n",
    "    feature_dicts = []\n",
    "\n",
    "    for _id in _ids:\n",
    "        feature_dict = {}\n",
    "        # get types and counts\n",
    "        query = \"\".join([\"SELECT type, type_count FROM counts WHERE work_id=\", str(_id), \" AND type REGEXP '^[A-Za-z]+$';\"])\n",
    "        #loop terms matching certain criteria (regex query)\n",
    "        a = cur.execute(query)\n",
    "        for row in cur:\n",
    "            #add to dict if ok to use\n",
    "            if row[0] in features:\n",
    "                feature_dict[row[0]] = row[1]\n",
    "        feature_dicts.append(feature_dict)\n",
    "\n",
    "    print(\"Finished making dictionaries\")\n",
    "    pickle.dump( feature_dicts, open( \"pickled_data/feature_dicts.p\", \"wb\" ) )\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "#convert to tf-idf model\n",
    "tfidf = TfidfTransformer()\n",
    "vec = DictVectorizer()\n",
    "vect = vec.fit_transform(feature_dicts)\n",
    "adjusted = tfidf.fit_transform(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'across'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "final_tuples = []\n",
    "#load feature dict from pickle\n",
    "a = list(vec.vocabulary_.items())\n",
    "a.sort(key=operator.itemgetter(1))\n",
    "b = [i[0] for i in a]\n",
    "b[91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = adjusted.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0006534334192912478,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00094984315790312419,\n",
       " 0.0014997392538735627,\n",
       " 0.0029372727339682559,\n",
       " 0.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[91] for i in data][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
